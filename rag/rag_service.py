from rag.vector_store import vector_store_service
from utils.prompt_loader import load_rag_prompts
from langchain_core.prompts import PromptTemplate
from model.factory import chat_model
from langchain_core.output_parsers import StrOutputParser
from utils.logger_handler import logger
from langchain_classic.retrievers import ContextualCompressionRetriever
from langchain_classic.retrievers.document_compressors.flashrank_rerank import FlashrankRerank
import redis.asyncio as redis  # ğŸ‘ˆ æ³¨æ„ï¼šè¿™é‡Œç”¨äº†å¼‚æ­¥ Redis
import hashlib
import json
import asyncio
import os
REDIS_HOST = os.getenv("REDIS_HOST", "localhost")
REDIS_PORT = int(os.getenv("REDIS_PORT", 6379))
def prompt_print(prompt):
    # è°ƒè¯•æ‰“å°
    print("="*20)
    print(prompt.to_string())
    print("="*20)
    return prompt

class rag_service:
    def __init__(self):
        # 1. åˆå§‹åŒ–åŒæ­¥ç»„ä»¶
        self.vector_store = vector_store_service()
        # æ³¨æ„ï¼šload_documents æš‚æ—¶ä¿æŒåŒæ­¥ï¼ˆå¦‚æœæ˜¯åº”ç”¨å¯åŠ¨æ—¶è¿è¡Œä¸€æ¬¡æ²¡é—®é¢˜ï¼‰
        # self.vector_store.load_documents([]) 
        
        self.prompt_text = load_rag_prompts()
        self.prompt_template = PromptTemplate.from_template(self.prompt_text)
        self.model = chat_model
        self.chain = self._init_chain()
        
        # 2. å…³é”®ï¼šä¸è¦åœ¨ init é‡Œåšå¼‚æ­¥æ“ä½œï¼Œè®¾ä¸º None
        self.retriever = None 
        self.redis_client = None

    async def initialize(self):
        """
        æ–°å¢ä¸€ä¸ªæ˜¾å¼çš„åˆå§‹åŒ–æ–¹æ³•ï¼Œä¸“é—¨å¤„ç†å¼‚æ­¥è¿æ¥
        """
        if not self.retriever:
            logger.info("æ­£åœ¨åˆå§‹åŒ–æ··åˆæ£€ç´¢å™¨...")
            self.retriever = await self.get_final_retriever()
        
        if not self.redis_client:
            try:
                self.redis_client = redis.Redis(
                    host=REDIS_HOST, port=REDIS_PORT, db=0, decode_responses=True
                )
                await self.redis_client.ping()
                logger.info("âœ… Redis (Async) è¿æ¥æˆåŠŸ")
            except Exception as e:
                logger.warning(f"âŒ Redis è¿æ¥å¤±è´¥: {e}")
                self.redis_client = None

    def _init_chain(self):
        chain = self.prompt_template | prompt_print | self.model | StrOutputParser()
        return chain

    def _get_cache_key(self, query: str) -> str:
        md5_hash = hashlib.md5(query.encode('utf-8')).hexdigest()
        return f"rag:cache:{md5_hash}"

    async def rag_sumarize(self, query: str):
        try:
            # 1. ç¡®ä¿åˆå§‹åŒ–å®Œæˆ (Lazy Init)
            if not self.retriever or not self.redis_client:
                await self.initialize()

            # 2. æŸ¥ç¼“å­˜ (Async)
            cache_key = self._get_cache_key(query)
            if self.redis_client:
                try:
                    cached = await self.redis_client.get(cache_key)
                    if cached:
                        logger.info(f"âš¡ï¸ å‘½ä¸­ Redis ç¼“å­˜, ç¼“å­˜: {cached}")
                        return cached
                except Exception as e:
                    logger.warning(f"Redis è¯»å–å¼‚å¸¸: {e}")

            logger.info("ç¼“å­˜æœªå‘½ä¸­ï¼Œæ‰§è¡Œ RAG æ£€ç´¢...")
            
            # 3. æ£€ç´¢ (Async invoke)
            documents = await self.retriever.ainvoke(query)
            
            context = ""
            for i, doc in enumerate(documents):
                context += f"æ–‡æ¡£{i+1}ï¼š{doc.page_content}\n"
            
            # 4. ç”Ÿæˆ (Async invoke)
            prompt_input = {"input": query, "context": context}
            response = await self.chain.ainvoke(prompt_input)
            
            # 5. å†™å…¥ç¼“å­˜ (Async)
            if self.redis_client:
                try:
                    await self.redis_client.setex(cache_key, 3600, response)
                except Exception as e:
                    logger.warning(f"Redis å†™å…¥å¼‚å¸¸: {e}")
                
            return response

        except Exception as e:
            logger.error(f"RAG æ‰§è¡Œè¿‡ç¨‹å‡ºé”™: {e}")
            return "æŠ±æ­‰ï¼Œç³»ç»Ÿæš‚æ—¶æ— æ³•æ£€ç´¢ä¿¡æ¯ã€‚"
            
        finally:
            # ğŸ§¹ã€å…³é”®ä¿®æ”¹ã€‘æ‰«å°¾å·¥ä½œï¼šæ¸…ç†æ‰€æœ‰ç»‘å®šåœ¨å½“å‰ Event Loop ä¸Šçš„èµ„æº
            if self.redis_client:
                await self.redis_client.aclose() # å…³é—­è¿æ¥
                self.redis_client = None         # é‡ç½®ä¸º None
            
            # Retriever å†…éƒ¨å¯èƒ½åŒ…å« Async Client (å¦‚ OpenAI HTTP Client)ï¼Œä¹Ÿéœ€è¦é‡ç½®
            # è¿™é‡Œçš„ vector_store æ˜¯åŒæ­¥åŠ è½½çš„ï¼Œä¸éœ€è¦é‡ç½®ï¼Œåªéœ€é‡ç½®æ£€ç´¢å™¨åŒ…è£…å™¨
            self.retriever = None 
            logger.info("ğŸ”„ èµ„æºæ¸…ç†å®Œæˆï¼Œå‡†å¤‡ä¸‹ä¸€æ¬¡è°ƒç”¨")
    
    async def get_final_retriever(self):
        # è¿™é‡Œè°ƒç”¨ vector_store é‡Œçš„å¼‚æ­¥æ–¹æ³•
        hybrid_retriever = await self.vector_store.get_hybrid_retriever()
        
        compressor = FlashrankRerank(model="ms-marco-MiniLM-L-12-v2", top_n=5)
        # æ³¨æ„ï¼šlangchain_classic å¯èƒ½éœ€è¦æ”¹ä¸º langchain.retrievers
        retriever = ContextualCompressionRetriever(
            base_compressor=compressor,
            base_retriever=hybrid_retriever
        )
        return retriever